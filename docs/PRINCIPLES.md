# Product Principles

Interview Conditioning Studio enforces interview-like constraints and never evaluates correctness. It captures objective behavioral signals (time usage, nudges, phase transitions) and mandatory user self-reflection, but does not judge solution quality. All data is local-first. The product succeeds when repeated sessions reduce user discomfort under interview pressure, regardless of solution outcomes.

## Core Invariants

1. **Constraints are enforced, not suggested.** Time limits, nudge budgets, and phase transitions are mandatory. Users cannot opt out of discomfort.

2. **No correctness evaluation.** The system never judges whether code is right or wrong. It observes behavior, not solutions.

3. **No AI interviewer.** The product does not simulate an interviewer, provide hints, or offer feedback during sessions.

4. **Local-first.** All session data stays in the browser. Nothing is uploaded unless the user explicitly exports.

5. **Reflection is mandatory.** Users must complete a brief self-assessment after each session. Skipping defeats the learning loop.

6. **Descriptive, not evaluative.** Summaries and historical comparisons present facts ("you used 2 nudges") without judgment ("that's too many").

## What This Product Is Not

- Not a leetcode alternative
- Not a coding assessment tool
- Not an AI tutor
- Not a leaderboard or gamification system

## Success Metric

After ~20 sessions, users should measurably handle pressure, silence, and structure better â€” even if their solutions are still imperfect.
